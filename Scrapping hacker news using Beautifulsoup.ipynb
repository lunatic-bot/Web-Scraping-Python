{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urllib\n",
    "import requests\n",
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = urllib.request.urlopen(\"https://news.ycombinator.com/\").read()\n",
    "\n",
    "soup = BeautifulSoup(source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Hacker News</title>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.name\n",
    "# u'title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hacker News'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string\n",
    "# u'The Dormouse's story'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.parent.name\n",
    "# u'head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p\n",
    "# <p class=\"title\"><b>The Dormouse's story</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(id=\"link3\")\n",
    "# <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for link in soup.find_all('a',{'class':'storylink'}):\n",
    "    links.append(link['href'])\n",
    "    votes.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for link in soup.find_all('a',{'class':'storylink'}):\n",
    "    titles.append(link.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_title = ([{'Link': links, 'Title': titles} for links, titles in zip(links, titles)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Link': 'https://lists.zx2c4.com/pipermail/wireguard/2020-December/006226.html',\n",
       "  'Title': 'Response to “WireGuard: great protocol, but skip the Mac app”'},\n",
       " {'Link': 'https://www.bbc.com/news/technology-55639920',\n",
       "  'Title': \"TikTok: All under-16s' accounts made private\"},\n",
       " {'Link': 'https://cp4space.hatsya.com/2021/01/08/the-neural-network-of-the-stockfish-chess-engine/',\n",
       "  'Title': 'The neural network of the Stockfish chess engine'},\n",
       " {'Link': 'https://community.signalusers.org/t/reminder-please-be-nice/21217',\n",
       "  'Title': 'Signal community: Reminder: Please be nice'},\n",
       " {'Link': 'https://www.excamera.com/sphinx/fpga-j1.html',\n",
       "  'Title': 'The J1 Forth CPU'},\n",
       " {'Link': 'https://mfkl.github.io/2021/01/13/half-a-million-downloads.html',\n",
       "  'Title': 'Milestone: Half a million downloads for VideoLAN packages in the .NET ecosystem'},\n",
       " {'Link': 'https://2020game.io/', 'Title': '2020 Game'},\n",
       " {'Link': 'https://www.workatastartup.com/jobs/41302',\n",
       "  'Title': \"Join YC's software team and help build Work at a Startup\"},\n",
       " {'Link': 'https://netzpolitik.org/2021/wolf-culture-how-huawei-controls-its-employees-in-europe/',\n",
       "  'Title': 'How Huawei controls its employees in Europe'},\n",
       " {'Link': 'https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store',\n",
       "  'Title': 'Distributing Mac apps outside the App Store, a quick start guide'},\n",
       " {'Link': 'item?id=25760960',\n",
       "  'Title': 'Ask HN: How do we build the new remote education system'},\n",
       " {'Link': 'https://perell.com/note/the-paradox-of-abundance/',\n",
       "  'Title': 'The Paradox of Abundance'},\n",
       " {'Link': 'item?id=25760750',\n",
       "  'Title': 'Ask HN: Do we need a Google Customers Union? Could it work?'},\n",
       " {'Link': 'https://reasonandmeaning.com/2017/10/31/what-is-social-cooling/',\n",
       "  'Title': 'What Is Social Cooling?'},\n",
       " {'Link': 'https://lwn.net/SubscriberLink/842319/8adb13e08d0302bd/',\n",
       "  'Title': 'Debian discusses vendoring again'},\n",
       " {'Link': 'https://people.csail.mit.edu/tzumao/diffvg/',\n",
       "  'Title': 'Differentiable Rasterizer for Vector Graphics'},\n",
       " {'Link': 'https://www.anandtech.com/show/16408/samsung-confirms-amd-rdna-gpu-in-next-exynos-flagship',\n",
       "  'Title': 'Samsung Confirms AMD RDNA GPU in Next Exynos Flagship'},\n",
       " {'Link': 'https://www.nytimes.com/2021/01/11/health/colonoscopy-health-home-testing.html',\n",
       "  'Title': 'A Colonoscopy Alternative Comes Home'},\n",
       " {'Link': 'https://gustedt.wordpress.com/2017/08/08/cross-language-interfaces-between-c-and-c/',\n",
       "  'Title': 'Cross Language interfaces between C and C++'},\n",
       " {'Link': 'https://www.nytimes.com/2021/01/11/science/brown-tree-snake-climbing.html',\n",
       "  'Title': 'Snakes Found a New Way to Slither'},\n",
       " {'Link': 'https://github.com/juicedata/juicefs',\n",
       "  'Title': 'A distributed Posix file system built on top of Redis and S3'},\n",
       " {'Link': 'https://lwn.net/SubscriberLink/840632/5120a4e4b44f7d2a/',\n",
       "  'Title': 'Some Unlikely 2021 Predictions'},\n",
       " {'Link': 'http://solarleaks.net/',\n",
       "  'Title': 'Solarwind, Fireeye, Microsoft and Cisco leaks are offered for sale'},\n",
       " {'Link': 'https://www.justice.gov/opa/pr/visa-and-plaid-abandon-merger-after-antitrust-division-s-suit-block',\n",
       "  'Title': 'Visa and Plaid Abandon Merger After Antitrust Division’s Suit to Block'},\n",
       " {'Link': 'https://michaelnaimark.medium.com/a-cheap-simple-hack-for-improving-your-online-classtime-experiences-802071cd34c1',\n",
       "  'Title': 'Cheap and simple way to mount a smartphone directly above a laptop display'},\n",
       " {'Link': 'https://blog.brownplt.org/2021/01/10/property-based-testing.html',\n",
       "  'Title': 'Teaching and Assessing Property-Based Testing'},\n",
       " {'Link': 'https://a16z.com/2012/01/19/management-debt/',\n",
       "  'Title': 'Management Debt (2012)'},\n",
       " {'Link': 'https://critter.blog/2021/01/12/if-it-matters-after-today-stop-talking-about-it-in-a-chat-room/',\n",
       "  'Title': \"If it will matter after today, don't talk about it in a chat room\"},\n",
       " {'Link': 'https://opensource.apple.com/source/clang/clang-23/clang/tools/clang/www/comparison.html',\n",
       "  'Title': 'Why Apple Chose Clang (2008)'},\n",
       " {'Link': 'https://threedots.ovh/blog/2021/01/drawbridge-what-sql-server-on-linux-is-built-on/',\n",
       "  'Title': 'Drawbridge: What SQL Server on Linux is built on'}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['333 points',\n",
       " '44 points',\n",
       " '185 points',\n",
       " '682 points',\n",
       " '97 points',\n",
       " '39 points',\n",
       " '121 points',\n",
       " '62 points',\n",
       " '206 points',\n",
       " '27 points',\n",
       " '14 points',\n",
       " '43 points',\n",
       " '216 points',\n",
       " '96 points',\n",
       " '50 points',\n",
       " '166 points',\n",
       " '25 points',\n",
       " '16 points',\n",
       " '78 points',\n",
       " '167 points',\n",
       " '41 points',\n",
       " '260 points',\n",
       " '556 points',\n",
       " '100 points',\n",
       " '19 points',\n",
       " '64 points',\n",
       " '692 points',\n",
       " '143 points',\n",
       " '42 points']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cp4space.hatsya.com/2021/01/08/the-neural-network-of-the-stockfish-chess-engine/\"\n",
    "\n",
    "source = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where exciting things happen\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('div',{'id':'site-description'}).string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Projective 4-Space\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('a').string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = soup.find('img')['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "#img = urllib.request.urlretrieve(img_url, \"image_{}\".format(i))\n",
    "img = urllib.request.urlretrieve(img_url, 'image1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image1', <http.client.HTTPMessage at 0x159fa4107c8>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  \n",
    "  \n",
    "# creating a object  \n",
    "im = Image.open(r\"00000001.jpg\")  \n",
    "  \n",
    "im.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_len = len(links)\n",
    "db_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_len = len(titles)\n",
    "db_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "votes = []\n",
    "a = soup.find_all('span',{'class':'age'})\n",
    "b = soup.find_all('span',{'class':'score'})\n",
    "for i range(len(a)):\n",
    "    if \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"age\"><a href=\"item?id=25759477\">4 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25760893\">1 hour ago</a></span>, <span class=\"age\"><a href=\"item?id=25759430\">4 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25757398\">10 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25759576\">4 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25760180\">2 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25759563\">4 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25760980\">59 minutes ago</a></span>, <span class=\"age\"><a href=\"item?id=25761068\">45 minutes ago</a></span>, <span class=\"age\"><a href=\"item?id=25757228\">10 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25760960\">1 hour ago</a></span>, <span class=\"age\"><a href=\"item?id=25746315\">2 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25760750\">1 hour ago</a></span>, <span class=\"age\"><a href=\"item?id=25746131\">10 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25758863\">6 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25747230\">6 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25755558\">13 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25747229\">3 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25760069\">3 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25746190\">8 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25747215\">11 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25758976\">6 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25754895\">14 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25753935\">15 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25757004\">11 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25738436\">4 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25757997\">8 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25751808\">17 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25755204\">14 hours ago</a></span>, <span class=\"age\"><a href=\"item?id=25758012\">8 hours ago</a></span>]\n"
     ]
    }
   ],
   "source": [
    "a = soup.find_all('span',{'class':'age'})\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "site_titles = []\n",
    "site_dis = []\n",
    "images = []\n",
    "\n",
    "\n",
    "for x in range(db_len):\n",
    "    url = links[x]\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        source = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(source, 'html.parser')\n",
    "    \n",
    "        #print(url)\n",
    "        site_titles.append(soup.find('a').string)\n",
    "        try:\n",
    "            site_dis.append(soup.find('div',{'id':'site-description'}).string)\n",
    "        except:\n",
    "            site_dis.append(None)\n",
    "        try:\n",
    "            img_url = soup.find('img')['src']\n",
    "            img = urllib.request.urlretrieve(img_url)\n",
    "            images.append(img)\n",
    "        except:\n",
    "            images.append(None)\n",
    "    except:\n",
    "        site_titles.append(None)\n",
    "        site_dis.append(None)\n",
    "        images.append(None) \n",
    "    \n",
    "print(len(site_titles))\n",
    "print(len(site_dis))\n",
    "print(len(images))\n",
    "print(len(votes))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_2 = zip(links, site_dis, images, site_title, votes) \n",
    "relation_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing a connection in MongoDB\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient('mongodb://127.0.0.1:27017')\n",
    "\n",
    "my_db = client['Hacker_news']\n",
    "\n",
    "siteinfo = my_db.siteinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1598517c848>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## storing link_title in MongoDB\n",
    "\n",
    "## Insert many is used to insert many records\n",
    "siteinfo.insert_many(link_title)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
